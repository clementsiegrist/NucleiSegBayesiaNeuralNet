{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clementsiegrist/segmentation_probabilisticDL/blob/main/pre_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFjCG5BmbGfz"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/clementsiegrist/segmentation_probabilisticDL/main/requirements.txt \n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iHBWMhLu61E"
      },
      "source": [
        "%%capture\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "api_token = {\"username\":\"bendidihab\",\"key\":\"6b534264cbd90d4cc3f040b1894cb226\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!kaggle competitions download -c data-science-bowl-2018\n",
        "!unzip /content/{/content}/competitions/data-science-bowl-2018/data-science-bowl-2018.zip\n",
        "!mkdir /content/train\n",
        "!mv -i /content/stage1_train.zip /content/train\n",
        "!cd /content/train && unzip /content/train/stage1_train.zip\n",
        "!mkdir /content/data && mkdir /content/data/train && mkdir /content/data/test\n",
        "!rm -rf /content/stage1_sample_submission.csv.zip /content/stage1_solution.csv.zip /content/stage1_test.zip /content/stage1_train_labels.csv.zip /content/stage2_sample_submission_final.csv.zip /content/stage2_test_final.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qc-SCGM2sd"
      },
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Y6PTQVPDnt"
      },
      "source": [
        "i = 1\n",
        "train_percent = 0.7\n",
        "data_size = 670\n",
        "dim = (640,480)\n",
        "path = '/content/train'\n",
        "list_subfolders_with_paths = [f.path for f in os.scandir(path) if f.is_dir()]\n",
        "train_size = int(data_size*train_percent)\n",
        "test_size = data_size - train_size\n",
        "for sub in list_subfolders_with_paths :\n",
        "  folder_types = [f.path for f in os.scandir(sub) if f.is_dir()]\n",
        "  if i < train_size : \n",
        "    os.mkdir('data/train/OP'+str(i))\n",
        "  else :\n",
        "    os.mkdir('data/test/OP'+str(i))\n",
        "  for f_type in folder_types :\n",
        "    if f_type.split('/')[-1] == 'masks': \n",
        "      onlyfiles = [f for f in os.listdir(f_type) if os.path.isfile(os.path.join(f_type, f))]\n",
        "      src = f_type + '/' + onlyfiles[0]\n",
        "      src1 = cv.imread(src)\n",
        "      for img in onlyfiles : \n",
        "        src2 = cv.imread(f_type + '/' + img)\n",
        "        alpha = 1\n",
        "        beta = 1\n",
        "        src1 = cv.addWeighted(src1, alpha, src2, beta, 0.0)\n",
        "      img = cv.resize(src1, dim, interpolation = cv.INTER_AREA)\n",
        "      if i < train_size :\n",
        "        cv.imwrite('data/train/OP'+str(i)+'/img_' + str(i) + '_class.png',img)\n",
        "      else :\n",
        "        cv.imwrite('data/test/OP'+str(i)+'/img_' + str(i) + '_class.png',img)\n",
        "    if f_type.split('/')[-1] == 'images':\n",
        "      onlyfiles = [f for f in os.listdir(f_type) if os.path.isfile(os.path.join(f_type, f))]\n",
        "      img_raw = cv.imread(f_type + '/' + onlyfiles[0])\n",
        "      img = cv.resize(img_raw, dim, interpolation = cv.INTER_AREA)\n",
        "      if i < train_size :\n",
        "        cv.imwrite('data/train/OP'+str(i)+'/img_' + str(i) + '_raw.png',img)\n",
        "      else :\n",
        "        cv.imwrite('data/test/OP'+str(i)+'/img_' + str(i) + '_raw.png',img)\n",
        "  i += 1\n",
        "!rm -rf /content/train /content/{"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8I5bpr_S9Lf"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/yuta-hi/pytorch-trainer\n",
        "!cd pytorch-trainer && python setup.py install\n",
        "!git clone https://github.com/IhabBendidi/pytorch_bayesian_unet \n",
        "!cd pytorch_bayesian_unet && pip install -r requirements.txt && python setup.py install\n",
        "\n",
        "\n",
        "!cp -r /content/data/train /content/pytorch_bayesian_unet/examples/cellular_segmentation/train\n",
        "!cp -r /content/data/test /content/pytorch_bayesian_unet/examples/cellular_segmentation/test\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIv_Wz_0XF_-",
        "outputId": "4b82a280-7d3b-423a-87fc-8cb43945cfd0"
      },
      "source": [
        "!python /content/pytorch_bayesian_unet/examples/cellular_segmentation/preprocess.py"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# train images: 467\n",
            "100% 467/467 [00:00<00:00, 2117.91it/s]\n",
            "# train labels: 467\n",
            "100% 467/467 [00:02<00:00, 178.77it/s]\n",
            "# test images: 203\n",
            "100% 203/203 [00:00<00:00, 1617.91it/s]\n",
            "# test labels: 203\n",
            "100% 203/203 [00:01<00:00, 178.83it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILvfovogYCSO",
        "outputId": "6f731957-3a36-4d23-ca71-90a5f4c35b23"
      },
      "source": [
        "!python /content/pytorch_bayesian_unet/examples/cellular_segmentation/train_and_test_epistemic.py --iteration 2000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: cuda:0\n",
            "# Minibatch-size: 2\n",
            "\n",
            "\rCollecting image files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting image files: 100%|█████████████████████| 1/1 [00:00<00:00, 82.73it/s]\n",
            "\rCollecting label files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting label files: 100%|█████████████████████| 1/1 [00:00<00:00, 92.35it/s]\n",
            "\rCollecting image files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting image files: 100%|█████████████████████| 1/1 [00:00<00:00, 98.34it/s]\n",
            "\rCollecting label files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting label files: 100%|█████████████████████| 1/1 [00:00<00:00, 99.80it/s]\n",
            "\rCollecting image files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting image files: 100%|████████████████████| 1/1 [00:00<00:00, 192.04it/s]\n",
            "\rCollecting label files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting label files: 100%|████████████████████| 1/1 [00:00<00:00, 238.86it/s]\n",
            "# classes: 2\n",
            "# samples:\n",
            "-- train: 421\n",
            "-- valid: 46\n",
            "iteration   main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J0                       1.85258e+08                          0.329827                  9.40561       \n",
            "\u001b[J100         97237       205057                0.950368       0.809718                  346.268       \n",
            "\u001b[J     total [##................................................]  5.00%\n",
            "this epoch [#######################...........................] 47.51%\n",
            "       100 iter, 0 epoch / 2000 iterations\n",
            "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
            "\u001b[J200         57748.2     130938                0.941022       0.826521                  683.225       \n",
            "\u001b[J     total [#####.............................................] 10.00%\n",
            "this epoch [###############################################...] 95.01%\n",
            "       200 iter, 0 epoch / 2000 iterations\n",
            "   0.29678 iters/sec. Estimated time to finish: 1:41:05.036512.\n",
            "\u001b[J300         32160.9     177526                0.981598       0.808265                  1019.29       \n",
            "\u001b[J     total [#######...........................................] 15.00%\n",
            "this epoch [#####################.............................] 42.52%\n",
            "       300 iter, 1 epoch / 2000 iterations\n",
            "   0.29716 iters/sec. Estimated time to finish: 1:35:20.884847.\n",
            "\u001b[4A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5okwP67roPF",
        "outputId": "a782c31f-7aaf-4d7e-9e3c-899e20ad3f9c"
      },
      "source": [
        "!python /content/pytorch_bayesian_unet/examples/cellular_segmentation/train_and_test_epistemic.py --test_on_test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: cuda:0\n",
            "# Minibatch-size: 2\n",
            "\n",
            "\rCollecting image files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting image files: 100%|█████████████████████| 1/1 [00:00<00:00, 65.08it/s]\n",
            "\rCollecting label files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting label files: 100%|█████████████████████| 1/1 [00:00<00:00, 99.60it/s]\n",
            "\rCollecting image files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting image files: 100%|████████████████████| 1/1 [00:00<00:00, 106.31it/s]\n",
            "\rCollecting label files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting label files: 100%|█████████████████████| 1/1 [00:00<00:00, 94.51it/s]\n",
            "\rCollecting image files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting image files: 100%|████████████████████| 1/1 [00:00<00:00, 140.60it/s]\n",
            "\rCollecting label files:   0%|                             | 0/1 [00:00<?, ?it/s]\rCollecting label files: 100%|████████████████████| 1/1 [00:00<00:00, 218.27it/s]\n",
            "# samples:\n",
            "-- test: 203\n",
            "Loaded a snapshot: logs/predictor_iter_00000150.pth\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pytorch_bayesian_unet/examples/cellular_segmentation/train_and_test_epistemic.py\", line 414, in <module>\n",
            "    main()\n",
            "  File \"/content/pytorch_bayesian_unet/examples/cellular_segmentation/train_and_test_epistemic.py\", line 401, in main\n",
            "    test_phase(predictor, test, args)\n",
            "  File \"/content/pytorch_bayesian_unet/examples/cellular_segmentation/train_and_test_epistemic.py\", line 167, in test_phase\n",
            "    pred, uncert = infer.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/inference/inferencer.py\", line 193, in run\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/inference/inferencer.py\", line 151, in predict\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/inference/inferencer.py\", line 162, in predict_core\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/links/mc_sampler.py\", line 123, in forward\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/models/unet/bayesian_unet.py\", line 185, in forward\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/models/unet/unet_base.py\", line 347, in forward\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_bcnn-1.1.0-py3.6.egg/pytorch_bcnn/models/unet/unet_base.py\", line 80, in forward\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\", line 136, in forward\n",
            "    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 2058, in batch_norm\n",
            "    training, momentum, eps, torch.backends.cudnn.enabled\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyDuLDl-tFAG"
      },
      "source": [
        "!cd .."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4OOWKbkMpnA",
        "outputId": "b6b46d4f-b5a9-43a5-ca2a-ccef1eeb0835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/clementsiegrist/deep_seg.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'deep_seg' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxTTQoeDNAn4",
        "outputId": "02acb247-ee8f-4393-941f-967cbfe679cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " !pip install keras==2.4 tensorflow==2.3 scikit-learn scikit-image numpy pillow matplotlib imutils pillow opencv-python "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.4 in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tensorflow==2.3 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.4) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.4) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (2.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (2.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied: dask[array]>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.12.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow==2.3) (51.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.7.0)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=0.5.0->scikit-image) (0.11.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzVhambEJ7q5",
        "outputId": "1e7388f3-2033-4cf6-910e-0efa6adf30b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd /content/deep_seg/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep_seg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02mQg3zeMwWd"
      },
      "source": [
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/cells/train\"\n",
        "validation_path = \"/content/drive/MyDrive/Colab Notebooks/cells/validation\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/cells/test\"\n",
        "test_batch_size = 4\n",
        "checkpoint_path = '/content/weights'\n",
        "input_size = (256, 256) \n",
        "target_size = (256, 256) # (height, width) of input_size should be divisible by 32\n",
        "num_class = 2\n",
        "# fine tuning\n",
        "train_batch_size = 4\n",
        "test_batch_size = 4\n",
        "validation_batch_size = 4\n",
        "learning_rate = 1e-4\n",
        "nb_epochs = 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBAlAv0JWJku",
        "outputId": "1596252f-bb06-4854-f458-2f0f0c19b7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNZlt4BjWUWj",
        "outputId": "8e3bda6d-14e8-41c7-bf4e-a9063ff59695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from unet_pipeline.main import main\n",
        "from unet_pipeline.generator import load_pretrained, train_val_gen\n",
        "import tensorflow.keras as keras"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdU6Rf0fWl1J",
        "outputId": "7c1487ca-e2a6-4cd4-fe34-e65aac9adc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "model_name = 'cell_seg.hdf5'\n",
        "model = main(train_path, train_batch_size, validation_path, validation_batch_size, nb_epochs)\n",
        "predict_on_test_and_plot(test_path, model_name=model_name, num=98)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3ef16de50612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cell_seg.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredict_on_test_and_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m98\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/deep_seg/unet_pipeline/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_path, train_batch_size, validation_path, validation_batch_size, nb_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                                                                              \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                                                                              \u001b[0mvalidation_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                                                                                              validation_batch_size)\n\u001b[0m\u001b[1;32m     16\u001b[0m     model = load_pretrained(checkpoint_path, train_generator, validation_generator, validation_batch_size,\n\u001b[1;32m     17\u001b[0m                             train_batch_size, nb_epochs, train_image_generator, validation_image_generator)\n",
            "\u001b[0;32m/content/deep_seg/unet_pipeline/generator.py\u001b[0m in \u001b[0;36mtrain_val_gen\u001b[0;34m(train_path, train_batch_size, validation_path, validation_batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m     train_image_generator = train_image_datagen.flow_from_directory(train_path, classes=['images'], class_mode=None,\n\u001b[1;32m     51\u001b[0m                                                                     \u001b[0;31m# no labels are returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                                                                     \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                                                     \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emAJenAOdqVd"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "model_name = 'cell_seg.hdf5'\n",
        "predict_on_test_and_plot(test_path, model_name=model_name, num=98)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}